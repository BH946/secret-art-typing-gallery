# 연구노트

**이번에 처음 Thymeleaf 를 사용하다보니 해당 과정을 나중에 참고용으로 간략히 기록할 목적**

* **빌드 : gradlew clean build 또는 gradlew build**
  * **참고로 캐싱되어있으면 배포해도 그대로라서 반드시 캐싱 초기화 필요 - 자세한건 구글링**
  * **웹도 보통 자동 캐시되므로 주의할 것**
* **마지막은 "모니터링" 부분! + "배경음악 안끊기게 삽입"** 
  * 모니터링은 해봤으니 굳이 추가는 안하고 생략!!
  * 배경음악은 index.html, lobby.html 에선 스피커모양을 "로딩" 모양으로 바꿔서 잠시 로딩중임을 표시하는게 나을듯 하다.
    * 나머지는 전부 header가 있는 페이지라서 header 부분을 고정하고, body만 reload 할 수 있는지 찾아봐야할듯 하다.
    * https://velog.io/@chappse6/thymeleaf-layout-dialect-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0
    * 배경음악 포기 ㅠㅠ (사이트에 삽입은 너무 간단하지만 유지가 넘 복잡)
* **쿠버네티스 배포전에 cafe24에 배포먼저 해두기 (급함)**
* **[쿠버네티스 초급](https://bh946.github.io/categories/gcp_kuber_bas) 보고 GCP로 배포해보자**
* **CI/CD : Jenkins vs github action**
  * github action은 사용해봤으니 PASS하고, **Jenkins 도전**

* **테스트코드도 잘 작성**

<br><br>

**<참고 html>**

* **index.html : 제일 처음 메인 소개화면**
* **lobby.html : 처음 화면 다음인 로비 화면**
* **gallery.html : 갤러리(전시회) 페이지별 화면**
* **gallery-item.html : Item 세부정보**
* **studio.html : 작품제작실(스튜디오) 화면**
* **studio-complete.html : 작품 제작완료 화면**
* **fragments -> 이부분을 많이사용중이라 이곳을 대부분 수정**
  * **head.html**
  * **header.html**
  * **footer.html**
  * **album.html**
  * **modal.html**
  * **scripts.html**
  * **item.html**

<br><br>

## 2023-12-26 ~ 최근(2024)

**GCP 무료 체험판으로 진행!**

**클러스터 개념 참고**

* **Node(컴퓨팅리소스-VM) -> Pod(컨테이너 실행시킴), Container(어플리케이션)**
* **쿠버네티스 클러스터(=아래그림 전체)**

![image](https://github.com/BH946/bh946.github.io/assets/80165014/c68de552-2acf-429e-a82a-22f8c56fdff1) 

<br>

**(1) GKE는 "도커 이미지" 파일을 사용하기에 jar파일을 도커파일로 바꿔 배포해야함.**

* Docker 이미지를 빌드하려면 애플리케이션과 Dockerfile이 필요
* 따라서 jar 파일 **"업로드"** 후 **Dockerfile 작성** 잘 해서 **"도커이미지 빌드"**
  * spring boot dockerfile 작성 방법 이런식으로 검색해서 따라하기
* 단, 앱에서 db는 메모리db 사용하게끔 수정후 빌드하자.
* [참고 문헌](https://velog.io/@appti/%EB%8F%84%EC%BB%A4%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%8A%A4%ED%94%84%EB%A7%81-%EB%B6%80%ED%8A%B8#dockerfile)

```shell
nano Dockerfile

FROM openjdk:17-jdk
LABEL maintainer="test"

# JAR 파일을 Docker 이미지로 복사 -> 도커 이미지로 jar파일 복사안하면 unable jar 오류
COPY secret-art-typing-gallery-0.0.1-SNAPSHOT.jar /app/secret-art-typing-gallery-0.0.1-SNAPSHOT.jar
# 작업 디렉토리 설정 -> 도커 작업 상황은 /app으로 가야 jar파일 바로 사용 
WORKDIR /app # app/경로에 jar복제했기 때문

ENTRYPOINT ["java","-Dspring.profiles.active=default","-jar","secret-art-typing-gallery-0.0.1-SNAPSHOT.jar"]
```

- Ctrl+X -> Y
  - 저장하고 에디터 종료하는것
- docker build -t docker-springboot:0.1 .
  - 이미지 이름은 docker-springboot 지정이고 태그는 0.1로 지정
- docker images
  - 도커 이미지 확인

![image](https://github.com/BH946/bh946.github.io/assets/80165014/8f278179-7480-4f1d-b71f-8347dd4a544d) 

- 도커 컨테이너로 실행해보는 방법은? (ex:5000포트)
  - docker run -p 5000:8080 --name my-app docker-springboot:0.1 **: 실행(docker run)**
    * `-p` 로 5000포트 출입을 8080포트에 매핑, `--name` 으로 원하는 컨테이너 이름지정 가능
  - docker run -p 5000:8080 --name my-app -d docker-springboot:0.1 : **백그라운드 실행**
    - `-d` 로 백그라운드 실행

`curl http://localhost:5000` 으로 테스트 (아래 사진) 정상확인

<img src="https://github.com/user-attachments/assets/8608c71f-ccde-4c48-bc75-ab62ccb243c4" alt="image" style="zoom:80%;" /> 

<br>

+) **Google Container Registry API** 사용하여 이곳에 **도커 이미지 저장**해두자. (GKE에서 사용하게)

- gcloud auth configure-docker asia-northeast3-docker.pkg.dev : 저장소 사용 위해 인증!
- docker build -t asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1 . : 도커 빌드!
  - 본인의 경우 project_id 가 vital-wavelet-381119
- docker push asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1 : **Registry에 push**

<img src="https://github.com/user-attachments/assets/f9341fc9-0b17-4fc0-a8bd-642fa2bc49f1" alt="image" style="zoom:80%;" /> 

<br>

**(2) GKE로 클러스터 환경 먼저 설치 후 사용자 인증**

- gcloud config set project 프로젝트ID

* gcloud config set compute/region asia-northeast3
* gcloud config set compute/zone asia-northeast3-a
  * 참고 : Region > Zone 로써 Region이 더 큰 개념입니다.
* gcloud container clusters create --machine-type=e2-medium --zone=asia-northeast3-a lab-cluster
  * **lab-cluster 이름**으로 클러스터 생성 -> 5분정도 소요
  * 혹시나 **Kubernetes Engine API has not been used ... 에러** 발생시 GCP에서 API 사용
  * GKE 클러스터 생성
    * **클러스터**는 하나 이상의 **"클러스터 Master 머신"과 "Worker 머신"**으로 구성됩니다.
      * "머신 = Node"로 보면 됩니다.
    * **노드**를 만들기 위해서는 컴퓨팅리소스가 필요한데, GCP에서는 가상머신(VM)으로 컴퓨팅리소스를 만듭니다.
      * GKE로 클러스터 생성시 자동으로 만들어주기 때문에 **직접 VM을 구축할 필요없다!!**(편리)
* gcloud container clusters get-credentials lab-cluster --zone asia-northeast3-a
  * 클러스터 사용에는 사용자 인증이 필수
  * 뒤의 zone은 클러스터 생성한 위치라고 생각하면 됨 (필수!)
  * **쿠버네티스 클러스터와 Cloud Shell은 다르기 때문에 인증**
  * 단, Cloud Shell에서 쿠버네티스 클러스터 생성했을 경우 해당 Shell에서는 자동으로 인증을 해놓기 때문에 바로 클러스터 정보를 조회하거나 사용이 가능


<br>

**(3) GKE로 배포, 서비스 - 타입은 로드밸런서 (create, expose로 생성)**

* Kubernetes의 Deployment 생성 -> create deployment 명령어
  * kubectl create deployment hello-server --image=asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1
  * 도커 이미지 경로가 앞에서 저장한 **Google Container Registry 에 위치**
* Kubernetes의 Service 생성 -> expose deployment 명령어
  * kubectl expose deployment hello-server --type=LoadBalancer --port 8080

`kubectl get pods` 와 `kubectl get service` 로 정상적으로 생성되었는지 확인

![image](https://github.com/user-attachments/assets/6766d582-6606-4bd1-981e-9be4182027b5)
![image](https://github.com/user-attachments/assets/009b71a8-a221-4746-a47e-03f125a5bd66) 

`http://외부IP:8080` 으로 테스트 (아래 사진) 정상확인

![image](https://github.com/user-attachments/assets/43c34455-180e-4b27-8b0d-404232de0628) 

<br>

**(4) Jenkins 로 CI/CD 까지 자동화 해보기 + 카나리아 업뎃 방식 사용해 볼 거임**

**Helm(패키지 관리자)을 사용해서 차트저장소에 Jenkins를 설치합니다.**

* **클러스터는 이미 생성 및 인증도 했으니 PASS**
* **예제 코드들다운(클론) -> 물론, Jenkins만 여기서 사용할 듯 - values.yaml**
  * gsutil cp gs://spls/gsp051/continuous-deployment-on-kubernetes.zip .
  * unzip continuous-deployment-on-kubernetes.zip
  * cd continuous-deployment-on-kubernetes

![image](https://github.com/user-attachments/assets/c1f508ef-ad29-4307-bc31-ed242cf33a63) 

* helm repo add jenkins https://charts.jenkins.io
  * Jenkins 차트가 저장되어 있는 저장소를 Helm에 추가하여 나중에 해당 차트를 검색하고 설치할 수 있게 한다.
  * helm search repo jenkins : Helm에 추가된 Jenkins 차트 저장소 설치 확인!
  * helm repo update : 저장소 최신 상태인지 확인!

![image](https://github.com/user-attachments/assets/cee1b9aa-1612-4128-8e60-f85d7423b963) 

- helm install cd jenkins/jenkins -f jenkins/values.yaml --wait : **진짜 Jenkins 설치**

  - Jenkins 설치할 때 `values.yaml` 을 통해서 연동에 필요한 플러그인들을 자동으로 설치

  - helm의 jenkins/jenkins 차트로 gsutil로 다운 받았던 values.yaml을 사용해서 jenkins를 설치

  - helm status cd : cd라는 이름으로 설정했으므로 cd 상태 체크로 설치 상태 확인 가능

    <details><summary>values.yaml 코드</summary>
    <div markdown="1">
    ```
    controller:
      installPlugins:
        - kubernetes:latest
        - workflow-job:latest
        - workflow-aggregator:latest
        - credentials-binding:latest
        - git:latest
        - google-oauth-plugin:latest
        - google-source-plugin:latest
        - google-kubernetes-engine:latest
        - google-storage-plugin:latest
      resources:
        requests:
          cpu: "50m"
          memory: "1024Mi"
        limits:
          cpu: "1"
          memory: "3500Mi"
      javaOpts: "-Xms3500m -Xmx3500m"
      serviceType: ClusterIP
      service:
        port: 8081
    agent:
      resources:
        requests:
          cpu: "500m"
          memory: "256Mi"
        limits:
          cpu: "1"
          memory: "512Mi"
    persistence:
      size: 100Gi
    serviceAccount:
      name: cd-jenkins
    ```
    </div>
    </details>

    <details><summary>에러.. 정상 설치가 안된다. -> 이상하게 다시 성공하긴 했다..? </summary>
    <div markdown="1">
    - 아마 프로덕션이 port:8080 이미 사용중이라 port:8081로 바꾸고 재설치 해보자
    - helm uninstall cd -n default : 로 helm cd 관련 다 제거(pod, svc 포함)
    - 위 values.yaml 코드에서 port:8081 추가해서 다시 재설치 했다.
    - 엥?? 막상 성공한 로그에는 port:8080을 사용한다. 흠? 근데 또 성공하긴 했다... 이상하네;;
    </div>
    </details>

  - kubectl get pods : 정상 설치 확인 (svc도 같이 확인 ㄱㄱ)

  - kubectl create clusterrolebinding jenkins-deploy --clusterrole=cluster-admin --serviceaccount=default:cd-jenkins : Jenkins 서비스 계정 설정

- 로컬 접근 위해 포트포워딩 (근데 이미 접근 되는것 같긴 한데 안 되면 이 명령어 쓰자)

  - export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/component=jenkins-master" -l "app.kubernetes.io/instance=cd" -o jsonpath="{.items[0].metadata.name}")
    - POD_NAME에 결국 cd-jenkins-0 라는 문자열이 저장 (pod 이름)
  - kubectl port-forward $POD_NAME 8080:8080 >> /dev/null &
    - 로컬 8080 포트 접근 시 -> pod 8080 포트로 연결 (=포트포워딩)
    - `>> /dev/null` 이거는 로그 출력 무시, `&`는 백그라운드 실행

![image](https://github.com/user-attachments/assets/7df4612a-622f-401e-9556-82715e697d14) 

- **따로 외부IP는 없으니까 위 정보를 사용해서 Cloud Shell의 웹 미리보기 포트 8080 클릭해서 접속합니다.**
  - ClusterIP: 클러스터 내에서만 접근 가능한 기본 서비스 유형
  - 참고로 Jenkins를 처음 생성할 때 자동으로 관리자 비밀번호를 설정하므로 확인이 필요
  - printf $(kubectl get secret cd-jenkins -o jsonpath="{.data.jenkins-admin-password}" | base64 --decode);echo : 비밀번호 확인 명령어
    - 따라서 관리자 ID : admin
    - 비밀번호 : 위에서 확인한 번호 -> 본인의 경우: dMordzg7DFfNWdXX2QWO12

![image](https://github.com/BH946/bh946.github.io/assets/80165014/4de1d24a-3fd7-4557-b329-921c359ce245) 

<br>

**이제 Jenkins 실행은 마쳤고, 앱 배포(복제본4개)와 카나리아 1개(업뎃방식) 를 배포해보자.**

/healthz 경로는 애플리케이션 코드에서 직접 구현해야 합니다. -> 우린 없으니까 이 설정은 없애는게 나을듯. 애초에 yaml로 안해서 해당 설정은 추가 안하면 되긴 할듯 ㅇㅇ. 우린 yaml이 아니라 하나하나 설정해야함. replicas 수동으로 설정하는 것 처럼

그럼 뭘 추가 설정해야하나?? 일단 해보고 추가하자. 어차피 우린 프론트, 백엔드 나뉜게 아니라 걍 앱 한개 사용하는게 끝이니까. -> 가능은 한데 그냥 yaml로 해야겠음!! 이게 일반적이라길래!!

**yaml이 일반적이라고 하니깐 yaml로 ㄱㄱ.**

- 우선 기존 프로덕션 배포는 다시 제거 하겠음 (docker image, pod, svc 전부!) -> Jenkins는 냅두고!

  - docker images, docker ps -a 확인해보니 없긴하네 -> 바로 pod, svc 만들었었던가?
  - kubectl delete svc hello-server 로 서비스 먼저 삭제
  - kubectl delete pods hello-server-6ddfc56d6d-wmvhj 로 포드 삭제
    - deployment로 관리되고 있어서 포드가 계속 재생성 되는 문제 -> deployment를 삭제
    - kubectl get deployments 로 이름 확인 후
    - kubectl delete deployment hello-server 로 삭제 완료! 포드도 다 삭제 됨!

- yaml 소스 작성해보자.(Dockerfile, jar있는 곳에!) -> 프로덕션.yaml, 카나리아.yaml, dev.yaml

  - 경로정리 -> my-app 폴더 만들어서 거기에 필요 파일들 관리하겠음.
    - mkdir my-app : 폴더생성
    - mv Dockerfile my-app/ : 파일이동(jar 파일도)
    - cd my-app : 경로이동

- **(3) GKE로 배포, 서비스 - 타입은 로드밸런서 (yaml로 생성)**

  - ```yaml
    nano k8s/production/production.yaml
    
    kind: Deployment
    apiVersion: apps/v1
    metadata:
      name: secret-full-production
    spec:
      replicas: 3
      selector:
          matchLabels:
              app: secret
              role: full
              env: production
      template:
        metadata:
          name: full
          labels:
            app: secret
            role: full
            env: production
        spec:
          containers:
          - name: full
            image: asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1
            resources:
              limits:
                memory: "500Mi"
                cpu: "100m"
            imagePullPolicy: Always
            ports:
            - name: full
              containerPort: 8080
    ```

  - ```yaml
    nano k8s/canary/canary.yaml
    
    kind: Deployment
    apiVersion: apps/v1
    metadata:
      name: secret-full-canary
    spec:
      replicas:
      selector:
          matchLabels:
              app: secret
              role: full
              env: canary
      template:
        metadata:
          name: full
          labels:
            app: secret
            role: full
            env: canary
        spec:
          containers:
          - name: full
            image: asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1
            resources:
              limits:
                memory: "500Mi"
                cpu: "100m"
            imagePullPolicy: Always
            ports:
            - name: full
              containerPort: 8080
    ```

  - ```yaml
    nano k8s/dev/dev.yaml
    
    kind: Deployment
    apiVersion: apps/v1
    metadata:
      name: secret-full-dev
    spec:
      replicas:
      selector:
          matchLabels:
              app: secret
              role: full
              env: dev
      template:
        metadata:
          name: full
          labels:
            app: secret
            role: full
            env: dev
        spec:
          containers:
          - name: full
            image: asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1
            resources:
              limits:
                memory: "500Mi"
                cpu: "100m"
            imagePullPolicy: Always
            ports:
            - name: full
              containerPort: 8080
    ```

  - ```yaml
    nano k8s/service/service.yaml
    
    kind: Service
    apiVersion: v1
    metadata:
      name: secret-full-svc
    spec:
      type: LoadBalancer
      ports:
      - name: http
        port: 80
        targetPort: 8080
        protocol: TCP
      selector:
        app: secret
        role: full
    ```

  - 도커 이미지는 앞에서 Google Container Registry 에 저장해둔게 있어서 이거 경로 ㄱ

    - 나중에 Jenkins로 자동 배포할 때 도커 이미지도 빌드 및 푸시를 제공할 수 있다 -> 본인은 Google Container Registry 에 푸시!
    - Jenkinsfile 로 파이프라인 작성하게 될 거임!

  - yaml에 command 라인은 제거했다. Dockerfile에 Endpoint 잘 정의해놨기 때문!!

    - 특히 포트는 **Spring에서 8080** 해놓긴 했었음

- 배포 해보자 -> 복제본 3개와 카나리아 1개로 하자

  - kubectl apply -f k8s/production
  - kubectl apply -f k8s/canary
  - kubectl apply -f k8s/service

배포 테스트 -> http://외부IP 접속도 정상 확인

<img src="https://github.com/user-attachments/assets/21688378-7fcb-4895-bd8a-b0a6cbfa1659" alt="image" style="zoom:80%;" /> 

<br>

**Jenkins 파이프라인을 만들어 보겠습니다.**

- kubectl port-forward cd-jenkins-0 8080:8080 >> /dev/null & : **jenkins 실행에 필수(웹 미리보기)**
  - 로컬(웹 미리보기) 8080 포트 접근 시 -> pod 8080 포트로 연결 (=포트포워딩)

- 깃 호스팅 ㄱㄱ

  - 샘플 앱의 복사본을 만들고 이를 Cloud Source Repository로 푸시ㄱㄱ **를 하려고 했으나 현재 지원 중단!! **따라서 직접 깃허브에 레포지토리를 추가해서 사용하겠다.****

    ```bash
    git init
    git config --global user.email "[EMAIL_ADDRESS]"
    git config --global user.name "[USERNAME]"
    git add .
    git commit -m "Initial commit"
    git remote add origin https://github.com/BH946/my-app.git
    git branch -M main
    git push -u origin main
    ```

  - 참고로 깃헙 로그인 때 비번입력은 이제 지원안해서 "토큰 or ssh"로 해결 ㄱㄱ

- Jenkins 대시보드 설정 -> **깃허브로 해야해서 다르게 해야함.**

  1. 서비스 계정 사용자 인증
     - Jenkins에서 GitHub 저장소에 접근하기 위해서는 GitHub 플러그인을 설치<br>`Manage Jenkins -> Manage Plugins -> Available 탭에서 "GitHub"를 검색하여 설치`
     -  `Jenkins 관리 > Manage Credentials > System > Global credentials > Add Credentials`
       * `Kind는 Username with password 선택 -> Username: GitHub 사용자 이름 -> Password: Personal Access Token (PAT) 사용 -> Create`
  2. Kubernetes용 Jenkins Cloud 구성
     - 구성방법 : `Jenkins 관리 > Manage Cloud > Clouds Add a new cloud > Kubernetes > Kubernetes Cloud Details`

       * Jenkins URL : `http://cd-jenkins:8080`
       * Jenkins tunnel : `cd-jenkins-agent:50000`
  3. Jenkins 작업 생성
     1. Dashboard(대시보드) > New Item(새 항목) 클릭
     2. 프로젝트 이름은 my-app으로 지정, Multibranch Pipeline(다중 브랜치 파이프라인) 옵션 선택 후 OK 클릭
     3. Branch Sources(브랜치 소스) 섹션에 있는 Add Source(소스 추가) 드롭다운에서 Git 선택
     4. Project Repository(프로젝트 저장소) 필드에 깃허브에 만든 레포지토리 주소 입력(http) : `https://github.com/BH946/my-app.git`
     5. 이전 단계에서 서비스 계정을 추가할 때 만든 사용자 인증 정보의 이름을 사용자 인증 정보드롭다운에서 선택
     6. Scan Multibranch Pipeline Triggers(다중 브랜치 파이프라인 트리거 검색)섹션에서 Periodically if not otherwise run(별도로 실행하지 않는 경우 주기적으로 실행)상자를 선택하고 Interval(간격) 값을 1분으로 설정
     7. `Branch Indexing`이라는 작업이 자동으로 실행되므로 `Finished: SUCCESS` 메시지 뜨면 성공!

- 이제 Jenkinsfile 을 설정(파이프라인 설정) ㄱㄱ

  - 본인 플젝에 맞춰 구한 Jenkinsfile<br>`nano Jenkinsfile`

    ```groovy
    pipeline {
        environment {
            PROJECT = "vital-wavelet-381119"
            APP_NAME = "docker-springboot"
            FULL_SVC_NAME = "secret-full-svc"
            CLUSTER = "lab-cluster"
            CLUSTER_ZONE = "asia-northeast3-a"
            IMAGE_TAG = "asia-northeast3-docker.pkg.dev/${PROJECT}/my-repository/${APP_NAME}:${env.BRANCH_NAME}.${env.BUILD_NUMBER}"
            JENKINS_CRED = "${PROJECT}"
            GCP_CRED = "99e295f9-753c-459d-9b77-1c814a4f83c3" // Jenkins에 등록한 GCP 자격 증명 ID
        }
    
        agent {
            kubernetes {
                label 'my-app'
                defaultContainer 'jnlp'
                yaml """
    apiVersion: v1
    kind: Pod
    metadata:
      labels:
        component: ci
    spec:
      serviceAccountName: cd-jenkins
      containers:
      - name: gcloud
        image: gcr.io/cloud-builders/gcloud
        command:
        - cat
        tty: true
      - name: kubectl
        image: gcr.io/cloud-builders/kubectl
        command:
        - cat
        tty: true
    """
            }
        }
    
        stages {
    
            stage('Build and Push Docker Image') {
                steps {
                    container('gcloud') {
                        withCredentials([file(credentialsId: env.GCP_CRED, variable: 'GOOGLE_APPLICATION_CREDENTIALS')]) {
                            sh """
                                # JSON 확인 위한 LOG
                                echo "Using credentials from: \$GOOGLE_APPLICATION_CREDENTIALS"
                                cat \$GOOGLE_APPLICATION_CREDENTIALS
                                gcloud config set project ${PROJECT}
                                # GCP 자격 증명을 활성화한 후 Docker 이미지 빌드 및 푸시
                                gcloud auth activate-service-account --key-file=\$GOOGLE_APPLICATION_CREDENTIALS
                                PYTHONUNBUFFERED=1 gcloud builds submit -t ${IMAGE_TAG} .
                            """
                        }
                    }
                }
            }
    
            stage('Deploy Canary') {
                when { branch 'canary' }
                steps {
                    container('kubectl') {
                        withCredentials([file(credentialsId: env.GCP_CRED, variable: 'GOOGLE_APPLICATION_CREDENTIALS')]) {
                            sh """
                                gcloud auth activate-service-account --key-file=\$GOOGLE_APPLICATION_CREDENTIALS
                                gcloud config set project ${PROJECT}
                                gcloud container clusters get-credentials ${CLUSTER} --zone ${CLUSTER_ZONE} --project ${PROJECT}
                                sed -i.bak 's#asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1#${IMAGE_TAG}#' ./k8s/canary/*.yaml
                                kubectl apply -f ./k8s/service
                                kubectl apply -f ./k8s/canary
                            """
                        }
                    }
                }
            }
    
            stage('Deploy Production') {
                when { branch 'main' }
                steps {
                    container('kubectl') {
                        withCredentials([file(credentialsId: env.GCP_CRED, variable: 'GOOGLE_APPLICATION_CREDENTIALS')]) {
                            sh """
                                gcloud auth activate-service-account --key-file=\$GOOGLE_APPLICATION_CREDENTIALS
                                gcloud config set project ${PROJECT}
                                gcloud container clusters get-credentials ${CLUSTER} --zone ${CLUSTER_ZONE} --project ${PROJECT}
                                sed -i.bak 's#asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1#${IMAGE_TAG}#' ./k8s/production/*.yaml
                                kubectl apply -f ./k8s/service
                                kubectl apply -f ./k8s/production
                            """
                        }
                    }
                }
            }
    
            stage('Deploy Dev') {
                when {
                    not { branch 'main' }
                    not { branch 'canary' }
                }
                steps {
                    container('kubectl') {
                        withCredentials([file(credentialsId: env.GCP_CRED, variable: 'GOOGLE_APPLICATION_CREDENTIALS')]) {
                            sh """
                                gcloud auth activate-service-account --key-file=\$GOOGLE_APPLICATION_CREDENTIALS
                                gcloud config set project ${PROJECT}
                                gcloud container clusters get-credentials ${CLUSTER} --zone ${CLUSTER_ZONE} --project ${PROJECT}
                                kubectl get ns ${env.BRANCH_NAME} || kubectl create ns ${env.BRANCH_NAME}
                                sed -i.bak 's#asia-northeast3-docker.pkg.dev/vital-wavelet-381119/my-repository/docker-springboot:0.1#${IMAGE_TAG}#' ./k8s/dev/*.yaml
                                kubectl apply -f ./k8s/service -n ${env.BRANCH_NAME}
                                kubectl apply -f ./k8s/dev -n ${env.BRANCH_NAME}
                                echo 'To access your environment run `kubectl proxy`'
                                echo "Then access your service via http://localhost:8001/api/v1/proxy/namespaces/${env.BRANCH_NAME}/services/${FULL_SVC_NAME}:80/"
                            """
                        }
                    }
                }
            }
        }
    
        post {
            success {
                echo '배포 성공!'
            }
            failure {
                echo '배포 실패!'
            }
        }
    }
    ```

    - Jenkins가 도커를 자동으로 제공하는건 아니므로 도커 플러그인을 설치하거나, Docker-In-Docker (DinD) 방식을 사용하거나 해야합니다. 하지만, Google Cloud Build를 사용하면 훨씬 쉽습니다. 얘는 내부적으로 도커 빌드 환경을 제공해주기 때문입니다.

      - `gcloud builds submit -t ${IMAGE_TAG} .` 이 명령어는 **Google Cloud Build**를 사용하여 Docker 이미지를 빌드하고 GCP의 **Artifact Registry**나 **Google Container Registry**에 저장하는 역할을 합니다. 즉, 실제로 Jenkins 자체에서 Docker 빌드를 수행하는 것이 아니라 **Cloud Build 서비스**에 해당 작업을 위임하고 있습니다.

      - 걍 기존에 **"Google Service Account from metadata"**로 설정했을 때는 GCP 메타데이터 서버를 통해 Jenkins가 GCP 리소스에 접근할 수 있는 권한을 자동으로 사용하고 있었습니다. 그러나 **"Username with password"**로 변경한 후에는 GitHub 저장소 접근에는 문제가 없을지 몰라도, GCP 클러스터와 같은 다른 리소스에 접근하는 데 필요한 인증 정보를 제공하지 않고 있어 문제가 발생하는 것입니다.
      - 흠.. 일단 Compute Engine 사용 계정보니 3223...계정이네 얘를 Jenkins에 등록ㄱ
      - ID흭득: 60700bb4-22b5-40aa-ba22-28df3979e8db -> withCredentials 코드 사용ㄱ
      - **시발 존나 안되네 Secret file로 다시 추가해서 해보겠음.**
      - ID흭득: 99e295f9-753c-459d-9b77-1c814a4f83c3
      - gcloud config set project ${PROJECT} -> 없어도 되면 지우기

    - 도커는 성공했고, 남은 kubectl apply!

      - 만약 main수정한거면? main deploy가 실행될거고 production pod와 svc aplly!!
        - 도커 image가 바뀌고 한다면 yaml내용도 바뀌는거니까 pod 재생성 될거임!
        - 물론, 그런거없이 별 차이 없으며 pod, svc 둘다 unchanged
      - 흠.. 자꾸 uncahnged가 뜨네?? -> ㅇㅋ 이미지 경로 문제였네~

    <details><summary><b>Jenkinsfile 문법 참고</b></summary>
    <div markdown="1"><br>
    - env.BRANCH_NAME과 env.BUILD_NUMBER를 사용하여 Docker 이미지 태그를 동적으로 생성
      - 만약 깃허브라면,
      - env.BRANCH_NAME: 현재 빌드가 실행 중인 Git 브랜치의 이름을 나타냅니다.
      - env.BUILD_NUMBER: 현재 빌드의 번호를 나타냅니다. 각 빌드는 고유한 번호를 가집니다.
    - Jenkinsfile에 더 다양한 소스들이 존재
      - Build and Push Docker Image: 도커 이미지 빌드 및 푸시
      - Deploy Canary: Canary 환경 배포
      - Deploy Production: 프로덕션 환경 배포
      - Deploy Dev: 개발 환경 배포
      - 배포 단계별 주요 특징
        - `when` 조건: 브랜치에 따라 다른 배포 수행 (다양한 배포 환경!)
        - `container()`: 특정 컨테이너에서 명령 실행
        - `sed` 명령: yaml 파일의 이미지 경로 동적 대체
        - `kubectl` 명령: Kubernetes 클러스터에 리소스 배포
      - sh 명령어 관려 코드 자세히
        - gcloud auth configure-docker: Google Container Registry에 Docker 인증 정보를 설정합니다. 이 명령어를 실행하면 Docker가 Google Container Registry에 이미지를 푸시할 수 있도록 인증됩니다.
        - docker build -t ${IMAGE_TAG} .: 현재 디렉토리(.)의 Dockerfile을 사용하여 Docker 이미지를 빌드합니다. 이미지 태그는 ${IMAGE_TAG}로 설정됩니다.
        - docker push ${IMAGE_TAG}: 빌드된 이미지를 Google Container Registry에 푸시합니다.
        - gcloud container clusters get-credentials: 지정된 클러스터에 대한 인증 정보를 가져옵니다. 이를 통해 kubectl 명령어를 사용할 수 있게 됩니다.
        - sed -i.bak 's#DOCKER_IMAGE_PLACEHOLDER#${IMAGE_TAG}#' ./k8s/canary/*.yaml: canary 디렉토리의 YAML 파일에서 DOCKER_IMAGE_PLACEHOLDER를 ${IMAGE_TAG}로 교체합니다. .bak 확장자의 백업 파일이 생성됩니다.
        - kubectl apply -f ./k8s/services: Kubernetes 서비스 리소스를 적용합니다.
        - kubectl apply -f ./k8s/canary: Canary 배포를 위한 리소스를 적용합니다.
        - kubectl get ns ${env.BRANCH_NAME} || kubectl create ns ${env.BRANCH_NAME}: 현재 브랜치 이름에 해당하는 네임스페이스가 존재하지 않으면 생성합니다.
        - sed -i.bak 's#LoadBalancer#ClusterIP#' ./k8s/services/frontend.yaml: 프론트엔드 YAML 파일에서 서비스 타입을 LoadBalancer에서 ClusterIP로 변경합니다.
        - kubectl apply -f ./k8s/services -n ${env.BRANCH_NAME}: 지정된 네임스페이스에 서비스를 적용합니다.
        - kubectl apply -f ./k8s/dev -n ${env.BRANCH_NAME}: 개발 환경 리소스를 적용합니다.
          마지막 두 줄은 로컬에서 서비스에 접근하는 방법을 안내합니다.
        - 등등.. 원하는 입맛대로 수정 가능
    </div>
    </details>

<br>

**마지막 테스트?**

1. **그외 branch -> dev (개발서버)**

   - git checkout -b new-feat<br>git add .<br>git commit -m "test : dev deployment"<br>git push origin new-feat

   - dev의 경우 "네임스페이스"를 생성했기에 독립적으로 pod, svc가 관리 가능하다.

   - 실제로 똑같은 service.yaml 파일을 사용했는데 1개 더 생성되었다! (외부IP도 그럼 2개!)

   - **네임스페이스: new-feat 으로 생성했음 (=깃헙 브랜치명)** 

2. **main branch -> production (운영서버)** 
   - 만약 카나리아를 운영서버로 업뎃하게 된다면 merge로 바로 CI/CD 간편!
   - git checkout main<br>
     git merge canary<br>
     git push origin main

3. **canary branch -> 카나리아 업뎃**
   - IP고정하고 싶으면? `sessionAffinity: ClientIP` 를 서비스 단 yaml에 추가

![image](https://github.com/user-attachments/assets/7d4e8423-1df2-41b5-b1a6-f700977acebc) 

![image](https://github.com/user-attachments/assets/e362f2b8-bb35-4df5-87cc-aa85c5debd57) 

**위 사진은 카나리아 적용되어 25%(4개 Pod중 1개) 확률로 업뎃한 배포가 출력!**

![image](https://github.com/user-attachments/assets/d2f7d0ee-1db3-4f37-b91e-59520d6be2fc) 

**위 사진은 canary 를 main과 merge하여 최종 업뎃한 배포 출력! 100%(4개 전부 최신 Pod)**

<br>

**배포기록**

![image](https://github.com/user-attachments/assets/3d83b772-4a4e-4b4c-a579-052ae13a4f7b) 

![image](https://github.com/user-attachments/assets/c0b1eef1-92b3-46fa-82ee-4390f1dd9d2c) 

**+ 참고 명령어**

- `kubectl rollout pause deployment/hello` : 중지합니다.
- `kubectl rollout resume deployment/hello` : 일시 중지를 다시 시작!
- `kubectl rollout undo deployment/hello` : 이전 버전으로 롤백입니다.
- `kubectl rollout history deployment/hello` : 기록 확인!
- `kubectl rollout status deployment/hello` : 출시 상태를 확인합니다.
- `kubectl get pods -L role` : 역할 확인 가능(=full)
- `kubectl get pods -o=jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].image}{"\n"}{end}'` : **JSONPath**를 사용해 모든 파드의 도커 이미지 path를 확인 가능

**JSONPath 활용한 도커이미지 path**

![image](https://github.com/user-attachments/assets/cd283862-0c0e-47d6-9580-c3b1ec925354) 

<br>

**결론: jar파일만 로컬에서 수정해서 업로드 후 다시 깃 push하면 이제 완벽히 GCP+Jenkins로 CI/CD**

- CI: 바뀐 내용을 Gradle로 빌드하고(이건 본인은 생략하고 바로 jar를 올림), Docker Image로 빌드한 후, Docker hub에 Push
- CD: Jenkins가 빌드한거 배포(Deploy)

<br>

**+) github action의 경우 어떤식? -> cafe24 서버호스팅 가정**

GitHub Actions와 Cafe24를 사용해 CI/CD 파이프라인을 구축하고 Docker 이미지를 배포하려고 할 때, 다음과 같은 일반적인 방법으로 진행할 수 있습니다:

### 1. 전체 프로세스 개요

1. **GitHub에 소스코드 수정 후 push**:
   - Main 브랜치에 수정된 소스를 push하면 **GitHub Actions**가 트리거됩니다.
2. **GitHub Actions의 CI/CD 파이프라인 실행**:
   - **테스트 코드 실행**: 먼저 테스트 코드를 실행하여 코드의 안정성을 검증합니다.
   - **Gradle 빌드**: Gradle을 이용해 애플리케이션을 빌드합니다.
   - **Docker 이미지 생성**: Docker를 사용해 프로젝트를 기반으로 이미지를 빌드합니다.
   - **Docker 이미지를 저장소에 푸시**: 빌드된 Docker 이미지를 **Docker Hub** 또는 **Google Container Registry(-> 요즘은 Artifact Registry 사용)**와 같은 외부 Docker 이미지 레지스트리에 저장합니다.
     - Docker Hub의 Public은 무료이지만, Private은 유료입니다.
     - 만약 유료를 사용할거면 Artifact Registry가 보안이 좋아서 더 좋습니다. (아마도..?)
3. **Cafe24 서버에서 Docker 이미지 가져와 실행 (SSH로 접속)**:
   - Cafe24 서버에서 GitHub Actions에서 빌드한 Docker 이미지를 가져와 실행합니다.
   - Cafe24 서버에 미리 Docker를 설치해야 정상 동작합니다.
     - 만약, 공유 호스팅 서버라면 루트권한이 제한되므로 Docker 설치가 제한될 수 있습니다.
     - 따라서 FTP로 서버에 jar파일을 보내고, java -jar 로 배포하는 전통방법이 해법이 될 수 있습니다.

<br><br>

## 2023-12-03

**할일 : 쿠버네티스 배포(도커이미지,웹서버-무중단배포) + 결과 보고서 작성**

* https://bh946.github.io/categories/gcp_kuber_bas
* https://willbfine.tistory.com/479
* 공부 후 바로 진행..!

이후 따로 추가로 할일 : 테스트코드 작성(연습겸), CI는 깃액션+CD는 Jenkins, 모니터링(웹에 모니터링은 처음)



""초급2 - 쿠버네티스 퀵 시작"" 이 부분 보고 따라하기. GKE를 사용해야 완성된 클러스터 환경을 자동 제공.

아니면 직접 VM을 깔고, 클러스터 환경처럼 세팅까지 수동으로 해야함. 따라서 GKE를 사용.

<br><br>

## 2023-09-30 ~ 10-04

**수정부탁받은 부분**

* 큰해상도에서도 모달 중앙정렬 부탁.. -> margin과 translate로 해결 완료
* 애니메이션 효과 지속적으로 변경 -> 10번 반복을 10000번으로 수정완료
* mail.png -> mail_new.png 변경 완료
* 나머지는 피그마 보고 수정 부탁했음(itemDetail의 이전,이후 버튼도 얘기있음 ㅜ)
  * 폰트 예제 이미지 띄우기. -> Modal로 해결하려 했으나 커스텀하기 좀 빡세서 직접 개발
  * 중간에 데이터 삭제시 itemDetail 페이지에서 이전, 이후 전시실 입장 버튼이 사라짐
    * 아마 +-1 밖에 범위가 안돼서 그럴거임
    * AUTO_INCREMENT 값을 초기화 후, 테이블 안의 모든 데이터의 ID값을 재조정하는 방법으로 해결
    * 애초에 ROWNUM() 을 활용해서 인덱스 관리하는듯 .
    * 그러나 나는 직접 페이징 하는 함수 해놨으니 그쪽 값을 활용해서 관리해보겠음!
      * **직접 함수를 만들어서 No 필드를 업데이트를 따로 해주는식으로 관리**
      * 새로 생성할때, 삭제할때 findAllWithNoPage 메소드.. 캐싱도 같이 적용.
      * **이제 id로 설정한 html들을 no으로 변경만 하면됨@**
    * 에러들... 발생.... 메소드를 수정하겠음... 여전히 No에 값 기록할거고... 생성, 삭제때 전체 게시물을 다  업데이트 시켜야겠음... ??
      * 고민... 아! pageId 로 해당 페이지를 알 수 있으니 그때 No 값도 알 수 있겠네.
      * 도출 공식 : No.? = totalCount-(10*(pageId-1)) -> 이것도 실패. 그냥 아래처럼.
      * **add, delete 할때 -> "캐시 초기화" + "일괄 수정" 으로 해결하자.**
      * **물론 다음에는 RowNum() 으로 해결하자. 쿼리에 이렇게 따로 기록하지말고!! 현재는 업데이트 쿼리문이 게시물수만큼 나갈수밖에 없기에 좋은 방안이 아님**
  * 화면 사이즈마다 마우스커서 크기 작게


<br>

**(개인적으로) 수정하고싶은 부분**

* GET으로 비번 인증없이 수정 부분으로 바로 넘어가는 문제
  * http://home2895.cafe24.com:8080/studioComplete/153 에서 뒤에 번호만 바꾸면 다 들어가짐
  * 따로 회원 로그인없이 페이지 구성해서 이런문제가 발생
  * 인터셉트 단계에 로그인 인증처럼 쿠키/세션 적용으로 해결하자
* url에 ?status=updateON 이런거 뜨는거 넘 별루 + 새로고침때 계속뜨는것도 없애보자.

<br><br>

## 2023-09-25~27

**디자인 추가 요청..**

* 4096x2304 비율에서 웹 엉망이 됨. 기존에는 1920x1024 화면 기준으로 만들었어서 발생한 문제
* 따로 해상도별로 디자인을 준게 아니기 때문에 다시 비율로 크기 변경해서 해결하겠음
  * **버그 -> container와 flex 같이쓰지말자 ,** , 이거때문에 이상하게 비율이 다 깨졌다.?.,

<br>

**캐싱 -> 정적파일 전부(속도개선)**

* gzip 압축 -> 보통 이미지나 동영상은 이미 압축되어 있는 상태가 대부분이라 HTML,CSS,JS 만 압축해도 충분!

<br>

**안한부분.. -> OK**

* **배경음악 - 파일받으면 적용(지금은 예시로 다른 bgm 적용)**
  * bgm 은 정책때문에 바로 자동재생을 못하게끔 하는편
  * 따라서 음소거 표시를 먼저 보여준후 사용자가 bgm사용유무를 받아내게끔 해야겠다.
  * 단 새로고침같이 redirect 일때가 문제... 음악이 끊기며 bgm이미지도 잘 안맞,
    * 자스로 해결하자. 클라이언트단에 책임지게하는게 효율적일듯.
    * 리다이렉트들 버튼마다 함수같이 연결
    * 음악 상태도 저장해놔서 bgm이미지도 맞추고, 바로 이어틀지 등등 활용하자
    * 솔직히 야매로 구현..생각보다 노가다네,, 원래 사람들은 어떻게 구현하려나,, ㅠㅠ
    * **배경음악 안끊기게 구현하고싶은데 포기..**
  * 자바스크립트로 여러함수를 만들고 scripts6 으로관리  
    스피커, 페이지번호, a태그와 button태그에 함수 전부추가햇음  
  
* **마우스 커서 변경**
* **폰트 폴더에 새로운 폰트..**
* **lobby.html 에 그림들 마저 수정 및 링크연결 + 그림들 받은 파일로 갈아끼우기!!**
  * 이거랑 받은 bgm 3개 하나로합쳐서 바꾸기 - OK
  * **배경음악 안끊기게 구현하고싶은데 포기.. -> 이거 꼭 얘기해주기 ㅠ**


<br><br>

## 2023-09-22-24

**index.html**

* 첫번째 레이아웃
  * 이미지 변경은 JQUERY hover 이벤트로 해결.
* 두번째 레이아웃
  * absolute 쓰면 rigth left 이런식으로 위치지정 바로 되고 중앙도 되고 하니까 바로바로 해결하자
  * 글자도 다 이미지로 저장되니까 다 이미지 배치 위주로 ...
* 세번째 레이아웃
* OK - 단, 음성이나 마우스라던지 이런거 안해서 안한것들 꼭 재확인

<br>

**lobby.html**

* 여기도 absolute !

<br>

**디자인 추가 요청사항**

* **1.전시실 정렬은 최신순부터! 가장 최근에 작성된 글이 1페이지에 나와야함**
  * pageId 구하는 함수랑 select할때 order by desc(내림차순) 으로 적용했다.
* **2.전시실 부분에 ‘1전시실 입장’ 요 버튼 호버했을 때 버튼 디자인 수정(이거 내가 설명 빼먹었음ㅠㅠ미안 피그마에 써놨다!)**
  * OK
  * 참고) hover 의 주의점 : 태그의 style이 제일 우선순위 높으므로 이쪽에 color, background-color 등이 있으면 지워주고 따로 \<style> 태그나 css에서 진행할것
    * 특히 .page-link:hover 과 .page-link.active 처럼 hover은 ":", active는 "." 사용하는 등의 자잘한 실수를 유발할 수 있으므로 꼼꼼히 살펴볼 것
* **3.작품제작실 - textarea 밑 설명글에서 ‘최대 30자’ 제거**
  * 따로 글자수 제한안걸어놔서 텍스트만 바로 제거완료
* **4.그리고 등록한 시간이랑 옆에 이미지 썸네일은 아직 반영 안된건지 궁금합니더**
  * 등록한 시간 문제없음
  * Gallery 의 썸네일은 수정완료
* 5.마우스 화살표 변경... 

<br><br>

## 2023-09-16

index.html, lobby.html 을 개발하자.

* 오래걸릴거같네 졸작먼저하자.

모니터링... -> 추후에..

<br><br>

## 2023-09-08~15

**리팩토링좀 진행 + 테스트 코드 추가 후 나머지 개발 시작하겠다.**

**테스트코드 - Junit4 사용**

* 다시 Junit5로 변경하긴 했음

```java
@RunWith(SpringRunner.class) // SpringRunner : Junit4
@SpringBootTest // 스프링과 통합 테스트 - "빈" 등 스프링 사용시 필수
public class ItemServiceTest { 
    @Test // 기본 테스트(필수)
    public void 조회() {} 
}
```

<br>

**리팩토링**

* (1) 외부 설정과 프로필
  * 특히 외부 파일의 내용을 사용하고 싶을때는 `@ConfigurationProperties` 로 자바객체로 바꿔 사용하는 방식 권장
    * "img 경로를 로컬, 서버 환경 세팅에 사용했음"
  * **새로만든 prod 프로필 사용시 실행법 `java -jar external-0.0.1-SNAPSHOT.jar --spring.profiles.active=prod`**
* (2) 타임리프1
  * 추천하는 "태그" 사용형태
    * 전체적인 틀!! container 클래스로 **\<div> 로 구간별 나누는것**이 젤 기본!
    * 데이터 간단히 표현할 때 : **\<table>+\<th>\<td>** 방식 보통 사용추천
      * **이미 div로 잘 구현해놔서 그냥`th:each` + `<th:block>` 만 추가 사용했음**
    * **"form 데이터는 label, input** 조합 권장", 이때 **th:field 와 *{...} 랑 th:object** 함께 사용권장!
      * th:field는 input이나 체크박스, 셀렉트박스 등에 사용하자!
      * 추가로 *{...} 랑 th:object로 한번에 데이터 관리하기 쉽게끔 사용하자!
  * 타임리프(@{}, |...|)문법 수정(아래 형태로 전부 수정)
    * **|...| : `<span th:text="|Welcome to our application, ${user.name}!|">`**
    * **@{} : 간편) -`th:href="@{|/basic/items/${item.id}|}"`**
  * **PRG 패턴** 반드시 확인-CHECKLIST -> 저장후 저장완료 표시 및 RedirectAttributes!!
    * 우리는 페이지를 다 이동하므로 저장완료 "메시지"를 출력하겠음
    * 추가로 forward 사용가능한건 forward 형태로!
* (3) 타임리프2
  * addForm, editForm은 따로 만드는게 좋아보이는데 이미 합쳐서 만들었으므로(=Modal) 그냥 이대로 진행!
  * "메시지-국제화" -> 진행완료 : `messages.properties, messages_en.properties` 확인
  * "검증" 진행!! + "자원재활용 -> Form에 빈 값"
    * 기존 엔티티인 Item 객체가 아닌 DTO에 "검증" 사용하는 구조를 사용하겠다
    * "검증"구현하다가 addForm, editForm 나눠서 구현안했더니 매우 봉변을 당하는중...
      * 그냥 나눠서 구현하게 바꾸겠음!! -> 모달만 한개 더 만들어서 적절히 모달을 선택하면될듯
      * 모달이 addForm, editForm 역할 할거임!!
    * "사용한 검증" - 비번 숫자@Pattern 정규식 사용!(클라에서도 따로 검증중), imgSrc에는  @NotBlank / id와 나머지들은 @NotNull 적용
  * "타입컨버터" 에서 ` @DateTimeFormat(pattern = "yy.MM.dd.HH:mm"), @DateTimeFormat(pattern = "yy년 MM월 dd일 HH시 mm분")` 사용
    * 타임리프 적용 : `th:field=*{{...}}`
* (4) 예외처리(오류페이지..) **=> 따로 꾸미진 않겠음**
  * BasicErrorController 규칙에 맞게끔 사용
    * `/error` 경로의 html을 접근

  * 뷰선택 우선순위(BasicErrorController 가 제공하는 기능)

    * **1. 뷰템플릿**
      * resources/templates/error/500.html
      * html resources/templates/error/5xx.html
    * **2. 정적리소스( static , public ) resources/**
      * static/error/400.html
      * resources/static/error/404.html 
      * resources/static/error/4xx.html
    * **3. 적용대상이없을 때뷰이름( error )**
      * resources/templates/error.html

* (5) "포트 수정 필요함" -> 개발용 8080 으로 열었는데, http는 기본 80을 사용해서 80으로 바꿔서 열자
  * **배포 버전에만 port를 80으로 수정했음**
  * **"로그 레벨"도 설정**
    * 배포는 기본값(info) 사용
    * 개발모드는 debug 사용했음
* (6) 스프링 3.x 로 **스프링 버전 업그레이드 진행**
  * JUNIT도 5로 바꾸겠음

<br>

**디자인 수정 부탁부분**

* (1) 헤더, 푸터 자잘한 수정 및 높이를 "고정" - 140px
  * .nav-item { font-size: 1.2vw; }
  * .nav-item-inner { font-size: 0.7em;}
  * 등등..
* (2) 전시실 수정 - 그림 높이 144px "고정" 등등...
  * 글자 길면 "..." 으로 잘리게끔... -> 너비 고정을해줘야 잘 적용되어서 width:25vw 비율로 진행
  * 버튼 위 마진 수정 등등
  * "페이지 번호 이동 UI 스타일링"
* (3) 전시실 세부
  * 모달 수정&삭제 부분은 비번치는것 밖에없음, 추가 부분이 많음
* (4) 스튜디오(제작실) - 디자인 수정 추가 부탁은 이게 마지막
  * 수정끝

<br>

**아래는 자잘한 수정**

나중에 gallery 조회시 캐시쓰는데 자꾸 count 쿼리 나가는 이유 찾기

* model.addAttribute("totalCount", itemService.findTotalCount()); 떄문인듯
* 해당부분은 캐시써서 캐시에 기록해두고, 추가나 삭제때만 바꾸자!!
* **OK 했음**

서버단에서 그냥 이미지 바로 저장해서 경로만 주고받는게 훨씬 나을듯... 이미지 base64 자체를 옮기려니까 너무 문자열이 길어서 문제가 많음.

* 그냥 바로 그림 생성하겠음. 추후에 갤러리에 없는 그림들은 따로 디스크에서 삭제하는 로직을 추가하던지 하면 되니까 !
* **OK**

Redirect의 status 활용해서 Alert 추가

* 컨트롤러에서 status 활용해서 update, delete, add 구분에도 추가 활용
* **OK**

이미지 2개씩 경로 저장된 문제

* add 할때 발생한 문제인데, 이때 파라미터로 따로 경로받고있는 상태에서 추가로 input을 hidden으로 따로 이미지 한번더 보냈기에 발생한 문제였다.
* 이에따라 add에는 input을 제거했고, update에만 input을 넣어서 이미지를 기록했다.
* **OK**

<br><br>

## 2023-09-04 자간, 행간 수정

**급하게 자간, 행간 간격만 수정할 필요가 있어서 이부분 수정**

<br><br>

## 2023-08-15 - 이미지 변환

**Static에 이미지추가햇는데 바로 서버단에서 갱신이 안되는 문제중**

* 보통은 외부 서버에(AWS S3 등) 이미지 파일같이 파일들을 저장 및 접근

* (static사용은 보안상 좋지는 않다고 하는것 같음)

* 결론은 이미지같이 동적 파일은 **외부 경로를 사용하는게 옳다.**

* 따라서 만약 서버에 배포할때는 해당 서버에 따로 이미지 폴더를 만들어서 해당 **경로를 매핑**

* 현재 로컬에서 개발중이라 로컬(윈도우) - `C:\images-spring` 경로로 지정했음.

* `WebMvcConfig` 하나 만들어서 `addResourceHandlers` 를 오버라이드해서 경로 매핑하면 됨.

  * `file:///` 뒤에 절대경로이며 위에 `/image/`는 매핑한 경로
  * 즉, 프론트에서 `/image/` 경로로 접근 요청하면 `file:///`뒤의 절대경로를 매핑해서 반환

  ```java
  @Configuration
  public class WebMvcConfig implements WebMvcConfigurer {
  
      @Override
      public void addResourceHandlers(ResourceHandlerRegistry registry) {
          registry.addResourceHandler("/image/**")
                  .addResourceLocations("file:///C:/images-spring/");
      }
  }
  ```

* 참고로 파일(이미지) 저장도 절대경로로 `C:/images-spring` 쪽에 저장

<br>

**핵심 기능들은 구현 완료했기 때문에 한동안 구현 멈추겠음. 그동안 스프링 공부와 서버 배포쪽으로 공부하고 오겠음.**

* 이후엔 추가기능이나 최적화위주로(예외처리, 최적화(쿼리), 레이아웃 수정 등)
* 배포할 때 thymeleaf 캐시다시 FALSE로 바꾸기

<br><br>

## 2023-08-14 - 이미지로 변환 -> 삽질...

**이미지 저장.. -> canvas 활용 및 base64 데이터로 db 기록 및 출력(img)**

* 화질 문제때문에 임의로 가상 태그를 넣어서 크기를 최대로 키운 글자를 캡처하는 방식으로 해결
  * 큰 이미지에서 작은 이미지로 바꾸는건 화질 손실이 별로 없겠지만, 작은 이미지에서 큰 이미지를 나타내는건 화질 손실이 많이 일어나기 때문에 이런 방식으로 변경
  * 확장자도 좀더 화질이 좋은 jpeg을 사용
  * 이미지 자체가 용량이 크지 않기 때문에 이와 같은 방식을 사용

* base64를 그대로 저장하는건 글자가 너무 길어서 DB에 저장하기도 까다롭고 많이 부하가 갈수도 있다 생각.
  * 보통 이미지는 db에 경로를저장하는식으로 ㅇㅇ 
  * 따라서 서버단에 이미지 저장해서 경로를 db에 기록해두겠음.

<br><br>

## 2023-08-11~12 - 폰트적용(핵심기능)

**StudioController.java를 조져보도록 하자..! 이거하고나면 한동안 Spring공부로 빠지겠음.**

```java
추후에 손봐야하는 함수.
/**
* 작품 완성 화면
* 이때 생성한 "앨범(사진)" 데이터가 함께 넘어올것임. -> 추후 해결하자.
*/
@GetMapping("studioComplete") // URL 매핑(GET)
public String studioComplete() {
return "studio-complete"; // studio-complete.html 반환
}
```

**타임리프 표현식관련 조건문**

* `th:text="${(item!=null) ? item?.id+'전시실' : '?전시실'}"`
  * 이런식으로 `${}` 로 감싸야 하는 특징을 잘 기억해두고, `item?` 처럼 ?를 함께사용하면 더욱 null safe하게 개발할 수 있다.

**page를 url로 바꾸기도 힘들고 하니 간단히 넣어둬야겠음(부트스트랩써서)**

* Pagination 사용 -> 페이지 3개에 + ... 하나 넣어야겠음, 유동적으로 ...을 hidden으로 가리던지 등등 하겠음

* 페이징로직을 자바스크립트로 해결하기위해 Jquery도 사용하겠음

* **타임리프 문법 자바스크립트 사용가능 inline으로!! css도 마찬가지!**

  * ```html
    <script th:inline="javascript">
    var pageCount = /*[[${(totalCount/10)+1}]]*/ null; // 총 페이지 크기 -> 통신으로 받음
        // 물론, /**/ 주석을 제거해도됨. 단지 빨간줄 떠서 추가함.
        // 문법은 [[${}]] 형태로 작성하면 됨.
    ```

<br>

**마지막 제일 중요한 기능인 "폰트".. 변환... 할 차례.**

현재 받은 폰트 파일은 WOFF(웹폰트), OTF(오픈타입포맷)  

* WOFF로 바로적용 (단, 한글만 적용. 영어는 X)
* 결국 그림으로 저장되게 할건데.. 그림은 너비높이가 비율은 유지한체로 반응형웹으로 크기 자동 변경되게끔 보여주면 될것 같다.
* 따라서 처음 제작할때도 비율을 유지하는게 맡는것같아서 적당한 비율을.. 고민..흠..
  * 디자인 받은건 1280x520 이었으니 이것을 비율로 바꿔서 고정하면 될것같네.(1:2.4)
  * 비율 고정하는건 간단히 하나의 값(예로vw)을 사용하면 됨. 
    * 1:2 -> 50vw:100vw
    * flex로 0.98:0.02 처럼 비율로 두개 나눴을때 한쪽이커져서 덮어씌어질경우 max-width:92% 이런식으로 지정해서 해결
* **폰트 입력은 성공했고, 뭐... 배경색이나 이런건 금방할테니.. 이후 이미지로 저장하는거만 하면**
* **기능아예 끝임.**



<br><br>

## 2023-08-10 - 페이징별 캐싱, 페이징

**아래 산으로 빠진 내용을 보고 gallery.html, product_detail.html이나 제대로 구현해보자.**

**잠깐만 산으로 빠져보자... ㅎㅎ 자꾸 이 캐시를 사용해서 최적화 하는게 마음에걸려서 ㅜ**

* 1000개정도 게시물이 있으면 1page에 10개씩 보여줌으로써 100page로 홈페이지 구성될거라 예상

  * 이 경우 캐시 사용시 오히려 캐시 메모리 사용량과 캐시 갱신에 많은 오버헤드 우려
  * **대신 페이지별로 캐싱을 권장**
    * DB접근때 페이징하는거랑도 관계가 좋아보임ㅇㅇ

* 매번 페이지별로(?page=1) url 접근하면 해당 페이지별로 데이터를 가져올거고(예로 데이터 10개) 이 데이터 처음가져올땐 캐시메모리에 기록하고 이후부터 메모리에서 빠르게 가져오기.

  * 그럼 page를 하나하나 100개 전부 접근하면 결국 1000개 데이터가 전부 캐시메모리에 기록되고, 오버헤드가 우려되지 않는가???
    * **오래된 캐시를 제거하는 등의 방법으로 해결**
    * 또한, 애초에 그런 접근은 악의적인 접근으로써 따로 보안로직을 구현해야한다고 생각
  * 그럼 게시물이 삭제되거나 수정되면?? 특히 삭제되면 페이지별 데이터 10개 구성한것도 9개가 되고 갱신도 되어야할거고 그럴텐데 이건 어떻게 해결할건데??
    * 게시물 삭제 시 캐시 업데이트 진행. **이때 삭제된 게시물 id로 해당 캐시를 무효화 하면 됨.**
    * 왜냐하면, 무효화 함으로써 캐시가 없기때문에 해당페이지 접근하는 사용자가있으면 새로 DB에 데이터를 불러올거기 때문. 또한, 불러와서 캐시에도 새롭게 기록될거임.
    * 특히, **이때 페이지별로 나눈 캐시를 사용**한 경우면, 해당 게시물이 속한 페이지의 캐시만 갱신하면 되는것. 모든페이지가 아니라.

* 마지막으로 페이지 당 게시물수 10개 고정일때 삭제되어도 다음페이지의 게시물로 채우는 방안

  * `SELECT * FROM 테이블명 ORDERS LIMIT 숫자(A) OFFSET 숫자(B)` 와 같이 limit, offset을 활용합니다.

    * 위 쿼리는 (**B+1**) 행 부터 **A** 행 만큼 출력을 합니다.
    * 예를 들어, `LIMIT 10 OFFSET 20`이면 21번째부터 30번째까지의 데이터를 가져오게 됩니다.
    * **단, JPQL에서는 limit, offset 키워드를 사용하지않고 setFirstResult(), setMaxResults() 를 사용해야 합니다.**

  * 이때, 스프링에서 제공하는 Pageable 클래스가있는데 아래코드처럼 작성해서 위 페이징하는 효과를 나타내게 도와주는 로직도 존재

    ```java
    public Page<Post> getPostsByPage(int pageNumber, int pageSize) {
        Pageable pageable = PageRequest.of(pageNumber - 1, pageSize);
        return postRepository.findAll(pageable);
    }
    ```

* 찐 마지막으로 캐시 메모리에 데이터도 제한이 가능한가??

  * ㅇㅇ 가능하다. 예를들면

    ```properties
    # application.properties
    spring.cache.cache-names=posts
    spring.cache.caffeine.spec=maximumSize=100 # 캐시 사이즈 설정 (예시로 최대 100개의 페이지를 캐시로 관리)
    ```

<br>

**페이징별 캐싱, 페이징 등등 수행완료.**

**참고로 마지막 최적화는 "예외처리 페이지" 진행할거임 ㅇㅇ**

gallery-item에서 "수정" 버튼은 비번입력후 studio-complete쪽으로 이동으로 보내는것으로 바꿨음

**낼부턴 StudioController.java 남았다고 볼 수 있:음.**

<br><br>

## 2023-08-08~09 - 기능 개발 시작 (캐시메모리 맛보기)

**금일부터는 기능개발을 주로 할거기 때문에 Thymeleaf와 Spring을 위주로 정리**

**기능은 우선 네비게이터 먼저 적용(페이지간 이동먼저. 이후 페이지 하나씩 정해서 상세기능구현)**

**Thymeleaf**

* **attr 문법을 이용하면 속성들 전부 th로 적용할 수 있음!! good**

  * `href="gallery.html" th:attr="href=gallery"`
  * 단, 링크를 `@{/gallery}` 이런 형태로 줘야 함. 위와같은 형태는 현재url에 계속 추가로 쌓이므로 문제가 발생할 수 있음

* 자동완성?? https://stackoverflow.com/questions/54155605/spring-tool-suite-autocomplete-content-assist-not-working-no-proposal-kinds/65047344#65047344

  * 귀찮아서 아직 보진않음

* **약간 items->item으로 여러개 ui형성해야하는?? 그런것도 fragments로 빼두면 훨씬 개발하기 편할듯 싶어서 gallery-item.html으로 하나 구상해야겠음.**

* **if문은 삼항연산으로 간단히 가능하며, for문은 th:each문을 활용하면 됨**

* 표현식을 정확휴ㅏ게 잘 사용할 것

  * 예로 `th:text="'No.'+${item.id}"` 이런식으로 작성해야함.
  * 또 `th:href="@{gallery/productDetail/(id=${item.id})}"` 이런식으로 여기선 또 `()` 로 감싸서 이렇게쓰면 url의 ?id=값 이런 파라미터로 넘어가는것.
  * 그냥 url에 이어쓰듯이 하는건` th:href="@{gallery/productDetail/{id}(id=${item.id})}"` 이렇게 하면 파라미터가 아니라 해당 값이 {id} 이쪽으로 적용되는것

* 그저 링크 이동을 하고싶은거면 즉, href를 쓸거면 <button이 아닌 <a태그 사용할 것.

  * button은 from데이터 넘긴다던지 이런용으로 보통 사용. -> form의 action으로 넘어가기 때문

* **꿀TIP!!! 웹 개발중인데 Thymeleaf 적용을 보려면 항상 Spring을 껏다 켜야한다. 이런 reload를 굉장히 간단히 하는설정이 존재!!**

  * thymeleaf의 캐시를 사용안하면됨. 이렇게하면 웹에서 새로고침하면 바로바로 변경사항 적용 -> **물론 개발때만 이렇게하고 배포할때는 캐시 사용하게 바꿔줘야합니다**

  * ```yml
    spring:
      thymeleaf:
        cache: false
        prefix: file:src/main/resources/templates/
    ```

**Spring**

* `Model` 클래스 활용 -> view에 데이터 보내서 간편히 보여줄 수 있는 클래스

* @RequestParam : 기존 url 쿼리 파라미터 방식 : ?userId=userA

* **@PathVariable("itemId") : 최신 트랜드인 경로 변수 방식 : /mapping/userA**

  - 중요한점은 @PathVariable 로 매핑한 userA가 따로 Model을 활용하지 않아도,
  - 백엔드 뿐만 아니라 프론트에서도 userA값을 사용가능하단 점이다.
  - (이부분은 추측이지만, 자동으로 변수를 추가해서 같이 프론트로 반환되는게 아닐까)
    - 스프링의 Model 클래스는 브라우저의 쿠키처럼 프론트에 같이 넘어가는 클래스
    - 이 때문에 데이터를 주고받기 수월
  - **물론, 햇갈릴수도 있어서 그냥 Model을 항상 데이터 보내는 용도로 사용하고,**
  - **@PathVariable을 url로 받은 값을 사용하는 목적으로 활용하는게 젤 좋아보임.**

* ```
  return "redirect:/gallery"; // 웹 요청을 다시 하는것(따라서 해당 함수를 실행)
  return "gallery"; // 평소처럼 gallery.html을 반환
  ```

<br>

**참고로 현재 최적화 없이 그냥 하고있음. 리액트나 그런건 HTTP통신으로 값가져왔을때 따로 상태변수로 잘 저장해서 관리할텐데 지금 타임리프에서 하고있는건 이러 ㄴ"상태변수"없는것 같음. 여기서 느껴지는게 리액트(웹)였으면 Redux같은 기술을 활용했을거고 리액트네이티브(앱)는 AsycnStorage 기술도 있고 방안이 다양한데, Thymeleaf는 확실히 SSR(서버사이드렌더링) 방식이다보니 서버쪽에서 해결하는게 맞는것 같다.**

* **최대한 이문제는 서버에서 해결해보겠ㅇㅁ(@Cacheable 이거 사용하면 될듯?)**
  * **[잘 정리한 사이트](https://adjh54.tistory.com/m/165) -> 이거보면 사용법이 다양함.**
  * 이부분에대해서 조금 알아보니 해결방안이 조금 보이는것 같다.
  * @Cacheable과 @CachePut 왼쪽꺼는 조회용, 오른쪽꺼는 저장용으로 사용하면 되며 "캐시"특성상 서버 메모리에 기록되는것이므로 @Cacheable로 조회하면 DB에 쿼리문을 날릴필요가 없이 자신의(서버) 메모리에서 값을 가져오면 되므로 훨씬 최적화가 된다고 생각한다.
    * 당연히 @Cacheable도 캐시에 저장하는데, 캐시에 값이 없을경우 저장한다는 특징이있고, @CachePut 은 값이 있어도 덮어씌운다고 생각하며 ㄴ된다.
  * 따라서 본인 생각에는 @CachePut을 게시물 **삭제, 수정, 추가** 이럴때에 추가로 적용해주고
  * 나머지 그냥 **조회**에는 @Cacheable을 다 적용하면 최적화가 될거라고 예상한다.
  * **적용후 결과는??**
    * `@EnableCaching` 꼭 이거를 해줘야 캐시 사용 선언을 하는것. 
      * 간단히 main함수쪽에 추가했음
    * `@Cacheable(value = "codeCache")` 이런식으로 value를 지정해줘야 '키'처럼 사용해서 식별할 수 있게 메모리에 저장할 수 있음.
    * **게시물 삭제, 수정, 추가에 @CachePut사용, 조회에 @Cacheable 사용함으로써 최적화 진행**

<br>

**우선은 기본적인 기능들을 다 구현하고 나면, 최적화 할 때 그 카페 전체게시물 보는것처럼 그부분은 보통 어떤식으로 구현해서 최적화를 하는지 알아둬야 할 듯 싶음.**

<br><br>

## 2023-08-07 - Modal(알림창) 사용

**stuido.html 레이아웃 구성완료**

* 어느정도 노하우가 생기기 시작
* 나머지 html 레이아웃도 오늘 다 제작하는것을 목표로

**알림창같이 창하나 더 띄우는건 Modal 을 활용**

* **모달의 경우 html에서 footer보다도 밑인 하단에 작성하는것을 권장.**
* 만약 footer위에하면 모달안에 footer가 딸려들어오는 구조로 적용됨

`&times;` 는 "X" 표시이다. 즉, close 버튼의 경우 버튼 내에 텍스트로 이것이 입력된 구조가 많다.

* 실제로 부트스트랩도 이구조이므로 버튼 X의 크기를 변경하고싶으면 font-size를 변경해야한다.

비밀번호 입력받을때 서버에서도 입력조건 처리하겠지만 프론트단에서도 먼저 처리해주고 서버에서도 처리해주면 더욱 안전

* 따라서 프론트단에서 정규식 검사하는 js 문법 활용
* onkeypress 방식을 사용했는데 이방식은 복붙을 구별하진 못해서 서버단에서도 처리해주는게 더욱 안전하다는 것

다양한 레이아웃 구성을 해보았고, 막히는 부분이있으면 지금까지 만든 레이아웃 코드를보자.

* 충분히 지금까지 한 코드 활용하면 원하는 레이아웃 어느정도 가능하다 판단됨

**꿀팁 -> 텍스트 가로 유지 -> `white-space: nowrap;` 스타일 적용**

<br><br>

## 2023-08-06 - 반응형 커스텀(Range) + 폰트 적용

**웹 폰트 SUIT를 사용중이라 이걸 css에 적용해보기**

* https://noonnu.cc/font_page/1150 로 css에서 적용 -> 지정한 font-family명으로 body에 font-family 속성에 적용
* `font-family: 'SUITE-Regular', sans-serif; ` 이렇게 적용함으로써 SUITE폰트 있으면 적용하고, 없으면 sans폰트 사용

**부트스트랩의 슬라이더를 사용하려면 Range 키워드 검색 -> 크기 커스텀은?**

* 크기 커스텀하는데 매우 많은 난항을 겪었다. 사실 크기를 고정했으면 전혀 문제가 없겠지만, 반응형으로 나타내기위 `vw, em` 을 사용하려고 노력했다.
* 특이사항으로 margin-top이 핸들에 적용이 되있는점을 확인했고, 이부분을 `vw, em` 을 적절히 활용해서 반응형에 맞게 수정했음
* 슬라이더 트랙이 "부모", 슬라이더 핸들이 "자식" 관계이므로 "자식" 에는 "부모" 의 비율에 맞게 반응형으로 사이즈 맞추기 위해 `em`을 활용했음.
  * **실제로 em은 "부모"의 font-size의 크기에 따라서 크기 결정됨**
  * **여기서 rem은?? -> em과 개념은 같은데 제일 root의 부모의 font-size를 따름**
  * **vw, vh는 뷰포트 화면(장치:예로 브라우저)크기에 따라 사이즈 결정됨**
  * **따라서 본인은 `vw, vh`로 "부모"부분 먼저 크기 결정후 `em`으로 "자식" 부분 크기 결정**
    * 여기서 꼭 부모부분에 font-size 안쓰더라도 설정해서 `em` 활용

<br><br>

## 2023-08-05 - 부트스트랩+타임리프 활용

**부트스트랩**

**아래 영상 참고해서 상단은 nav, 하단은 footer 를 사용할거임**

* **nav : https://www.youtube.com/watch?v=ox6_XCyJ9GY&list=PLRx0vPvlEmdAZ-wT8pwVJn5GBp5a5aVGy&index=3**
* **footer : https://www.youtube.com/watch?v=JH1UirUO1jA&list=PLRx0vPvlEmdAZ-wT8pwVJn5GBp5a5aVGy&index=6**
* 참고로 두가지의 경우 보통 좌우 꽉채우므로 `container-fluid` 사용도 괜찮음

**`flex:1` 를 이용해서 부피 확장하는것 참고(가끔 이걸로 해결됨)**

흠.. 자꾸 본문 전체를 하나의 컨테이너로 묶어서 개발하려고 했는데, 생각해보니... 보통 홈페이지는 내용이많으면 그만큼 스크롤바로 아래로 내려서 본다.

즉, 굳이 한화면에만 나타내려 할 필요가 없는것 같다. 따라서 본문에선 뷰 하나하나씩 차례로 아래로 쌓아가면서 만들어보겠다. 크기들을 최대한 잘 보이게끔 해서.

**참고로 `row` 에 margin 있기 때문에 필요없을땐 꼭 `m-0` 으로 직접 커스텀 필요**

<br>

**타임리프**

* `fragment + replace` 사용해서 nav, footer같은 반복해서 적는 부분들 재사용
  * 당연히 서버 실행해야 적용 - 타임리프 문법이기 때문

<br><br>

## 2023-08-04 - 부트스트랩 맛보기

**태그**

* 본문 보통 `<p>`, 본문 세부 스타일링은 `<span>`, 링크 연결(클릭 커서바뀌는) `<a>` 등등 태그별로 역할들이 있으니 잘 참고

**부트스트랩**

* grid 방식(flex방식도 많이사용)으로 레이아웃 전체 틀을 구성하려함 -> **반응형 row, col**
  * row안에 `col-sm-2, col-sm-10` 처럼 총합 12가 grid의 한행의 끝을 의미
  * **즉, 한행은 12열로 이루어짐**
  * **`<div class="row text-center align-items-center">` 이런식으로 중앙정렬**
    * `text-center` : 텍스트 중앙 정렬(좌우)
    * `align-items-start,center,end` : items 정렬이므로 자신의 자식들 정렬
    * `align-self-start,center,end` : self 정렬이므로 자신이 정렬
    * **참고로 align... justify... 이것들 정렬은 flex에서 주로 사용하므로 flex에서 사용할것**
* **`<img class="img-fluid>` 로 반응형 img 가능, `fs-4` 등등은 반응형 text 가능**
  * **본인은 `fs-4` 도 좋지만 직접 `vw,vh,em` 같이 size를 적절히 많이 주는중**
  * **vw, vh, 50% 등등 반응형에 맞게끔**
* `<nav class="navbar navbar-expand-md">` 로 nav 요소를 열어줌(expand-sm 등등)
  * `<div class="collapse navbar-collapse" id="navbarNav">` 은 collapse로 한줄에 표시해주는 느낌에다가 화면작을때 햄버거형태(토글버튼같은)로 보여주는 반응형
  * **`class=navbar` 가 padding이 있기 때문에 없애고 싶으면 padding:0을 style 지정**
    * **class에 p-0나 pt-0(위)...등등**
    * **또한, flex-direction도 row로 지정되어있어서** 필요시 column으로 변경가능
      * **간단히 class에 flex-column으로 지정 가능**
* **`bg-info, primary, secondary` 등등으로 백그라운드 컬러 간단히 테스트로 지정가능(개발하기에 용이)**
* `p-0, m-0` 등등으로 padding, margin 바로 적용 가능

* **반복(재사용)되는것들만 일반css로 따로 커스텀 사용하고 별거아닌건 인라인으로 바로 작성하자!**

* **border은 항상 style을 solid라던지 스타일 지정을해줘야 적용이 되는듯**
  * 참고로 굵기는 꼭 width를 같이 붙여줄것

* img 태그의 경우 혼자쓰는 태그이므로 이곳에 postion-relative, absolute는 불가능하므로 이를 감싸는 상위 태그에 relative를 적용해서 사용하는것을 권장

<br><br>

## 2023-08-03 - 시작(분석..)

* **타임리프(docs) : https://www.thymeleaf.org/doc/tutorials/3.1/usingthymeleaf.html#including-template-fragments**
* **부트스트랩(docs) : https://getbootstrap.com/docs/5.3/components/navbar/#toggler**

보통 부트스트랩(css) + Thymeleaf 로 웹개발 진행  
**본인은 `부트스트랩(css) + 피그마(css) + Thymeleaf` 로 진행**

**Youtube자료(옛날꺼긴 함) + Thymeleaf 공문 자료 참고(문법 등등)**

MVC 패턴으로 API 개발은 이미 해봤기 때문에 웹 관련해서만 기록중 ..

<br>

**VSCode**가 html 형식을 더 잘 지원해준다고 해서 VSCode로 html은 개발

물론 서버로 실행은 **Spring**에서 실행 -> Ctrl+F5로 빠르게 reload -> 추후 설정을 통해서 탬플릿 바로바로 reload되게 설정할 것

**먼저 피그마로 받은 웹페이지 9개?? 레이아웃 개발 진행 -> 기능은 나중에 개발**

* css, img 등등 정적파일은 static 폴더로 전부 빼두기 
* **부트스트랩을 사용하는 이유는 반응형 웹을 간편히 정의하기 위해**
  * 부트스트랩은 수많은 것을 제공해준다. **예를들어, 폰트사이즈의 경우??**
    * font-size:100px; 이런식으로 작성시 100**px**로 글자가 **"고정"**
      * **따라서 원래 em, rem, vw, vh 같은 단위를 사용해줘야 한다.**
    * **그러나 부트스트랩의 경우??**
      * **fs-1, fs-2** 등등 글자 크기를 제공해주는데 이것을 사용하면 매끄럽게 **반응형 웹을 제공**한다.
    * 단, 직접 커스텀해야하는 부분들도 존재한다. **예를들어, flex의 경우??**
      * 기존엔 display: flex, flex:1 이런식으로 적용했는데, 부트스트랩에서는 display:flex는 제공하지만, flex:1이 없다.
      * 따라서 이런부분은 직접 css 커스텀을 해줘야 한다.
        * `<div class="d-flex custom-header-flex">` 커스텀 한 예시이다.
        * 뒤의 custom-header-flex 부분은 따로 css 선언을해서 flex:1을 적용한 방식
        * d-flex는 부트스트랩이 제공하는 display:flex를 의미
  * **여기서 결론은??**
    * **반응형 웹으로 개발을 위해 최대한 부트스트랩의 기능을 활용하고,**
    * **없는부분만 따로 css 로 커스텀 하자는것!**
      * 본인은 피그마로 디자인을 받았다보니 직접 커스텀이 더 많아서 `em, vw, vh` 단위를 많이 사용했음
      * **참고 : vw, vh는 viewport(예로 웹화면)크기를 기준이며, em은 바로 부모의 font-size를 기준으로 반응함.**

<br><br>
